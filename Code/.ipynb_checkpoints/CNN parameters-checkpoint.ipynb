{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import winsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=42, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CNN(Epochs, Batch_size, seed=1):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # load data\n",
    "    cleaning = \"\"\n",
    "\n",
    "    input_location = \"../Data/Cleaned\" + cleaning + \"/bank-full_cleaned.csv\"\n",
    "    output_location = \"../Logs/CNN_outputs\" + cleaning + \"/CNN_%s_%s_%s.txt\"\n",
    "\n",
    "    df = pd.read_csv(input_location)\n",
    "\n",
    "    X = np.array(df.drop('y', axis=1))\n",
    "    y = np.array(df['y'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed)\n",
    "    \n",
    "    X_train, y_train = transform_xy(X_train, y_train)\n",
    "    X_test, y_test = transform_xy(X_test, y_test)\n",
    "\n",
    "    # create model\n",
    "    model = create_model()\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(12, input_dim=42, activation='relu'))\n",
    "#     model.add(Dense(8, activation='relu'))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# sparse_categorical_crossentropy\n",
    "    \n",
    "    # Fit the model\n",
    "    epochs = 10\n",
    "    batch_size = 100\n",
    "    model.fit(X_train, y_train, epochs=Epochs, batch_size=Batch_size, verbose=0)\n",
    "\n",
    "    train_scores = model.evaluate(X_train, y_train)\n",
    "#     print(\"\\nmetric names = \", model.metrics_names)\n",
    "#     print(\"train scores = \", train_scores)\n",
    "    print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], train_scores[1]*100))\n",
    "\n",
    "    scores = model.evaluate(X_test, y_test,verbose=0)\n",
    "#     print(\"\\nmetric names = \", model.metrics_names)\n",
    "#     print(\"test scores = \", scores)\n",
    "#     print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "    print('Test score:', scores[0])\n",
    "    print('Test accuracy:', scores[1])\n",
    "\n",
    "    # calculate predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    print(predictions)\n",
    "    # round predictions\n",
    "    rounded = [round(x[0]) for x in predictions]\n",
    "#     print(rounded)\n",
    "\n",
    "\n",
    "    # df_y_test = pd.DataFrame(y_test)\n",
    "    # df_y_test_predictions = pd.DataFrame(df_y_test)\n",
    "    conf_matrix = confusion_matrix(y_test,rounded)\n",
    "#     print(conf_matrix)\n",
    "\n",
    "    TN = conf_matrix[0][0]\n",
    "    TP = conf_matrix[1][1]\n",
    "    FN = conf_matrix[1][0]\n",
    "    FP = conf_matrix[0][1]\n",
    "    Accuracy = (TP+TN)/(TN+TP+FN+FP)\n",
    "    Sensitivity = TP/(TP+FN)\n",
    "    Specificity = TN/(TN+FP)\n",
    "    print(\"\\nAccuracy = \", Accuracy)\n",
    "    print(\"Sensitivity = \", Sensitivity)\n",
    "    print(\"Specificity = \", Specificity, \"\\n\")\n",
    "\n",
    "    with open(output_location%(Accuracy, Epochs, Batch_size), \"w\") as f:\n",
    "        f.write(\"train score =\"+ str(train_scores[1])+\"\\n\")\n",
    "        f.write(\"test score =\"+ str(Accuracy)+\"\\n\")\n",
    "        f.write(str(conf_matrix)+\"\\n\")\n",
    "        f.write(\"Accuracy = \"+ str(Accuracy)+\"\\n\")\n",
    "        f.write(\"Sensitivity = \"+ str(Sensitivity)+\"\\n\")\n",
    "        f.write(\"Specificity = \"+ str(Specificity)+\"\\n\")\n",
    "        # f.write(str(model.summary()) + \"\\n\")\n",
    "        f.write(str(model.get_config()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32416/33908 [===========================>..] - ETA: 0s\n",
      "acc: 90.38%\n",
      "10816/11303 [===========================>..] - ETA: 0s\n",
      "Accuracy =  0.901972927541\n",
      "Sensitivity =  0.426819923372\n",
      "Specificity =  0.96399279856 \n",
      "\n",
      "31840/33908 [===========================>..] - ETA: 0s\n",
      "acc: 90.58%\n",
      "10720/11303 [===========================>..] - ETA: 0s\n",
      "Accuracy =  0.904096257631\n",
      "Sensitivity =  0.501915708812\n",
      "Specificity =  0.956591318264 \n",
      "\n",
      "33600/33908 [============================>.] - ETA: 0s\n",
      "acc: 90.66%\n",
      "10208/11303 [==========================>...] - ETA: 0s\n",
      "Accuracy =  0.904450145979\n",
      "Sensitivity =  0.478927203065\n",
      "Specificity =  0.9599919984 \n",
      "\n",
      "33600/33908 [============================>.] - ETA: 0s\n",
      "acc: 90.80%\n",
      "10784/11303 [===========================>..] - ETA: 0s\n",
      "Accuracy =  0.905511811024\n",
      "Sensitivity =  0.478927203065\n",
      "Specificity =  0.961192238448 \n",
      "\n",
      "33408/33908 [============================>.] - ETA: 0s\n",
      "acc: 90.77%\n",
      "11200/11303 [============================>.] - ETA: 0s\n",
      "Accuracy =  0.90383084137\n",
      "Sensitivity =  0.44214559387\n",
      "Specificity =  0.964092818564 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=42, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "eps = [i*5 for i in range(1,6)] #[5, 10, 15, 20, 25]\n",
    "for ep in eps:\n",
    "    print(\"------\")\n",
    "    print(\"epoch = \", ep)\n",
    "    print(\"------\")\n",
    "    CNN(ep, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "batch size =  10\n",
      "------\n",
      "33504/33908 [============================>.] - ETA: 0s\n",
      "acc: 90.59%\n",
      " 9824/11303 [=========================>....] - ETA: 0s\n",
      "Accuracy =  0.902238343803\n",
      "Sensitivity =  0.481992337165\n",
      "Specificity =  0.957091418284 \n",
      "\n",
      "------\n",
      "batch size =  20\n",
      "------\n",
      "32160/33908 [===========================>..] - ETA: 0s\n",
      "acc: 90.51%\n",
      "11136/11303 [============================>.] - ETA: 0s\n",
      "Accuracy =  0.902415287977\n",
      "Sensitivity =  0.518007662835\n",
      "Specificity =  0.952590518104 \n",
      "\n",
      "------\n",
      "batch size =  30\n",
      "------\n",
      "32096/33908 [===========================>..] - ETA: 0s\n",
      "acc: 90.50%\n",
      " 9952/11303 [=========================>....] - ETA: 0s\n",
      "Accuracy =  0.902149871715\n",
      "Sensitivity =  0.524137931034\n",
      "Specificity =  0.95149029806 \n",
      "\n",
      "------\n",
      "batch size =  40\n",
      "------\n",
      "33440/33908 [============================>.] - ETA: 0s\n",
      "acc: 90.50%\n",
      "10528/11303 [==========================>...] - ETA: 0s\n",
      "Accuracy =  0.901884455454\n",
      "Sensitivity =  0.504980842912\n",
      "Specificity =  0.953690738148 \n",
      "\n",
      "------\n",
      "batch size =  50\n",
      "------\n",
      "33216/33908 [============================>.] - ETA: 0s\n",
      "acc: 90.50%\n",
      "10400/11303 [==========================>...] - ETA: 0s\n",
      "Accuracy =  0.902769176325\n",
      "Sensitivity =  0.491954022989\n",
      "Specificity =  0.956391278256 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=42, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "bs = [i*10 for i in range(1,6)]\n",
    "for size in bs:\n",
    "    print(\"------\")\n",
    "    print(\"batch size = \", size)\n",
    "    print(\"------\")\n",
    "    CNN(5, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 50, 75, 100, 125]\n",
      "------\n",
      "batch size =  25\n",
      "------\n",
      "33792/33908 [============================>.] - ETA: 0s\n",
      "acc: 90.51%\n",
      "10304/11303 [==========================>...] - ETA: 0s\n",
      "Accuracy =  0.901795983367\n",
      "Sensitivity =  0.524904214559\n",
      "Specificity =  0.95099019804 \n",
      "\n",
      "------\n",
      "batch size =  50\n",
      "------\n",
      "33504/33908 [============================>.] - ETA: 0s\n",
      "acc: 90.42%\n",
      "10976/11303 [============================>.] - ETA: 0s\n",
      "Accuracy =  0.902946120499\n",
      "Sensitivity =  0.498850574713\n",
      "Specificity =  0.955691138228 \n",
      "\n",
      "------\n",
      "batch size =  75\n",
      "------\n",
      "33728/33908 [============================>.] - ETA: 0s\n",
      "acc: 90.40%\n",
      "10944/11303 [============================>.] - ETA: 0s\n",
      "Accuracy =  0.904096257631\n",
      "Sensitivity =  0.478927203065\n",
      "Specificity =  0.959591918384 \n",
      "\n",
      "------\n",
      "batch size =  100\n",
      "------\n",
      "31904/33908 [===========================>..] - ETA: 0s\n",
      "acc: 90.38%\n",
      " 9632/11303 [========================>.....] - ETA: 0s\n",
      "Accuracy =  0.902415287977\n",
      "Sensitivity =  0.427586206897\n",
      "Specificity =  0.964392878576 \n",
      "\n",
      "------\n",
      "batch size =  125\n",
      "------\n",
      "32832/33908 [============================>.] - ETA: 0s\n",
      "acc: 90.30%\n",
      " 9888/11303 [=========================>....] - ETA: 0s\n",
      "Accuracy =  0.901972927541\n",
      "Sensitivity =  0.405363984674\n",
      "Specificity =  0.966793358672 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=42, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "bs = [(i*25) for i in range(1,6)]\n",
    "print(bs)\n",
    "for size in bs:\n",
    "    print(\"------\")\n",
    "    print(\"batch size = \", size)\n",
    "    print(\"------\")\n",
    "    CNN(5, size)\n",
    "\n",
    "winsound.Beep(400,300)\n",
    "winsound.Beep(300,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33248/33908 [============================>.] - ETA: 0s\n",
      "acc: 91.27%\n",
      "10112/11303 [=========================>....] - ETA: 0s\n",
      "Accuracy =  0.904804034327\n",
      "Sensitivity =  0.588505747126\n",
      "Specificity =  0.946089217844 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=42, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "CNN(100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18314176245200003\n",
      "-0.020704140827999984\n"
     ]
    }
   ],
   "source": [
    "print(0.588505747126-0.405363984674)\n",
    "print(0.946089217844-0.966793358672)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "winsound.Beep(400,300)\n",
    "winsound.Beep(300,300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D,Convolution2D,Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33908/33908 [==============================] - 16s    \n",
      "\n",
      "acc: 88.30%\n",
      "11264/11303 [============================>.] - ETA: 0s\n",
      "Accuracy =  0.882686012563\n",
      "Sensitivity =  0.122605363985\n",
      "Specificity =  0.981896379276 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, LSTM, Dense, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "def create_model():\n",
    "# ValueError: Error when checking model input: expected embedding_2_input to have shape (None, 300) but got array with shape (33908, 42)\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(20000, 128, input_length=42))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(64, 5, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=4))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     model.fit(data, np.array(balanced_labels), validation_split=0.5, epochs=3)\n",
    "    return model\n",
    "CNN(5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, LSTM, Dense, Conv1D, MaxPooling1D, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-156-12dc13c74895>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#     model.fit(data, np.array(balanced_labels), validation_split=0.5, epochs=3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-29d3e34f80dc>\u001b[0m in \u001b[0;36mCNN\u001b[1;34m(Epochs, Batch_size, seed)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEpochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mtrain_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kieron\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    843\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 845\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    846\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mC:\\Users\\Kieron\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1485\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1487\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kieron\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1140\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1141\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kieron\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m-> 2073\u001b[1;33m                               feed_dict=feed_dict)\n\u001b[0m\u001b[0;32m   2074\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2075\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kieron\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kieron\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kieron\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Users\\Kieron\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kieron\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, LSTM, Dense, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "def create_model():\n",
    "# ValueError: Error when checking model input: expected embedding_2_input to have shape (None, 300) but got array with shape (33908, 42)\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(20000, 128, input_length=42))\n",
    "#     model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(64, 5, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=4))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     model.fit(data, np.array(balanced_labels), validation_split=0.5, epochs=3)\n",
    "    return model\n",
    "CNN(5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.core import Activation, Dense, Flatten, Dropout, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'compile'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-3a3c255f0212>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#     model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#     model.add(Dropout(0.25))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-29d3e34f80dc>\u001b[0m in \u001b[0;36mCNN\u001b[1;34m(Epochs, Batch_size, seed)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#     model.add(Dense(1, activation='sigmoid'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'compile'"
     ]
    }
   ],
   "source": [
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.core import Activation, Dense, Flatten, Dropout, Reshape\n",
    "\n",
    "def create_model():\n",
    "    input_shape = (33908,42)\n",
    "    model = Sequential()\n",
    "#     model.add(Reshape((1,1,42), input_shape=(42,)))\n",
    "    model.add(Reshape(input_shape + (1, ), input_shape=input_shape))\n",
    "\n",
    "#     model.add(Activation(activation=\"relu\"))#, input_shape=(42,)))\n",
    "    model.add(Convolution2D(64, (3, 3)))#, border_mode='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Convolution2D(64, 3, 3, border_mode='valid'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "CNN(5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33908 42\n",
      "11303 42\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 33, 42)            462       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1, 42)             0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 42)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 42)                1806      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 43        \n",
      "=================================================================\n",
      "Total params: 2,311.0\n",
      "Trainable params: 2,311.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "33792/33908 [============================>.] - ETA: 0s\n",
      "acc: 88.25%\n",
      "10240/11303 [==========================>...] - ETA: 0s\n",
      "Accuracy =  0.884543926391\n",
      "Sensitivity =  0.0\n",
      "Specificity =  1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filters: Integer, the dimensionality of the output space (i.e. the number output of filters in the convolution).\n",
    "# kernel_size: An integer or tuple/list of a single integer, specifying the length of the 1D convolution window.\n",
    "Filters = 42\n",
    "Kernel_size = (10,)\n",
    "# input_shape = (42,)\n",
    "def create_model():\n",
    "#     input_shape = (33908,42)\n",
    "###     input_shape = (42,33908)\n",
    "    input_shape = (42,1)\n",
    "#     input_shape = (1,42)\n",
    "\n",
    "    model = Sequential()\n",
    "#     ValueError: The first layer in a Sequential model must get an `input_shape` or `batch_input_shape` argument.\n",
    "#     model.add(Dense(12, input_dim=42, activation='relu'))\n",
    "#     model.add(Convolution2D(input_shape=(42,),filters=Filters, kernel_size=Kernel_size))\n",
    "#     model.add(Reshape((33908, 42), input_shape=(33908,42), return_sequences=True))\n",
    "#     model.add(Reshape((None,33908,42), input_shape=(33908,42)))\n",
    "#     model.summary()\n",
    "#     model.add(Reshape(input_shape, input_shape=input_shape))\n",
    "#     model.summary()\n",
    "#     model.add(Conv1D(filters=Filters, kernel_size=Kernel_size))\n",
    "    model.add(Conv1D(filters=Filters, kernel_size=Kernel_size,input_shape=input_shape))#, padding='same'))\n",
    "#     model.summary()\n",
    "#     model.add(Reshape(input_shape+(1,), input_shape=input_shape))\n",
    "\n",
    "    model.add(MaxPooling1D(pool_size=(22,)))\n",
    "#     model.summary()\n",
    "#     model.add(Conv2D(32, 3, 3, activation='relu', input_shape=(None,)))\n",
    "    model.add(Flatten())\n",
    "#     model.add(Dense(42,activation='sigmoid'))\n",
    "    \n",
    "    model.add(Dense(42,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "#     model.add(Activation('softmax'))\n",
    "#     model.addActivation('sigmoid')\n",
    "#     model.summary()\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Reshape((33908,1,42), input_shape=(None,1,42)))\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def transform_xy(x,y):\n",
    "#     y = np.expand_dims(y, axis=2)\n",
    "    y = np.expand_dims(y, -1)\n",
    "#     x = np.expand_dims(x, axis=2)\n",
    "#     x = to_categorical(x, num_classes=42)\n",
    "#     y = to_categorical(y, num_classes=2)\n",
    "#     print(x.shape[0],x.shape[1])\n",
    "    x = np.reshape(x, (x.shape[0], x.shape[1],1))\n",
    "    \n",
    "#     print(y.shape[0])#,y.shape[1])\n",
    "#     y = np.reshape(y, (y.shape[0],1))#, x.shape[1]))\n",
    "#     y = to_categorical\n",
    "#     print(x.shape[0],x.shape[1],x.shape[2])\n",
    "\n",
    "#     x = x.reshape(x.shape[0],42 ,1)\n",
    "#     print(x)\n",
    "#     y = np.reshape(y, (1, y.shape[0], y.shape[1]))\n",
    "    return x,y\n",
    "CNN(5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33344/33908 [============================>.] - ETA: 0s\n",
      "acc: 88.28%\n",
      "Test score: 0.315322260698\n",
      "Test accuracy: 0.884986286827\n",
      "[[ 0.02966737]\n",
      " [ 0.06925065]\n",
      " [ 0.18592022]\n",
      " ..., \n",
      " [ 0.27927461]\n",
      " [ 0.25720465]\n",
      " [ 0.06312077]]\n",
      "\n",
      "Accuracy =  0.884986286827\n",
      "Sensitivity =  0.00842911877395\n",
      "Specificity =  0.999399879976 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Filters = 10\n",
    "Kernel_size = (20,)\n",
    "def create_model():\n",
    "    input_shape = (42,1)\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=Filters, kernel_size=Kernel_size,input_shape=input_shape, padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=(10,)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(42))#,activation='relu')\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def transform_xy(x,y):\n",
    "    y = np.expand_dims(y, -1)\n",
    "    x = np.reshape(x, (x.shape[0], x.shape[1],1))\n",
    "    return x,y\n",
    "CNN(5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32896/33908 [============================>.] - ETA: 0s\n",
      "acc: 89.57%\n",
      "Test score: 0.250178309697\n",
      "Test accuracy: 0.895514465192\n",
      "[[ 0.0246307 ]\n",
      " [ 0.03229559]\n",
      " [ 0.63297105]\n",
      " ..., \n",
      " [ 0.4876526 ]\n",
      " [ 0.73895782]\n",
      " [ 0.02969318]]\n",
      "\n",
      "Accuracy =  0.895514465186\n",
      "Sensitivity =  0.315708812261\n",
      "Specificity =  0.971194238848 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Filters = 10\n",
    "Kernel_size = (20,)\n",
    "def create_model():\n",
    "    input_shape = (42,1)\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=Filters, kernel_size=Kernel_size,input_shape=input_shape, padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=(10,)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(42,activation='relu'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def transform_xy(x,y):\n",
    "    y = np.expand_dims(y, -1)\n",
    "    x = np.reshape(x, (x.shape[0], x.shape[1],1))\n",
    "    return x,y\n",
    "CNN(5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32768/33908 [===========================>..] - ETA: 0s\n",
      "acc: 92.44%\n",
      "Test score: 0.241915764408\n",
      "Test accuracy: 0.896222241883\n",
      "[[  1.88318943e-03]\n",
      " [  5.95122809e-04]\n",
      " [  2.16790661e-01]\n",
      " ..., \n",
      " [  1.07139554e-02]\n",
      " [  6.35322481e-02]\n",
      " [  2.30170599e-07]]\n",
      "\n",
      "Accuracy =  0.896222241883\n",
      "Sensitivity =  0.530268199234\n",
      "Specificity =  0.94398879776 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Filters = 10\n",
    "Kernel_size = (20,)\n",
    "def create_model():\n",
    "    input_shape = (42,1)\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=Filters, kernel_size=Kernel_size,input_shape=input_shape, padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=(10,)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(42,activation='relu'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def transform_xy(x,y):\n",
    "    y = np.expand_dims(y, -1)\n",
    "    x = np.reshape(x, (x.shape[0], x.shape[1],1))\n",
    "    return x,y\n",
    "CNN(100,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP\n",
    "acc: 91.27% <br />\n",
    "Accuracy =  0.904804034327<br />\n",
    "Sensitivity =  0.588505747126<br />\n",
    "Specificity =  0.946089217844 <br />\n",
    "\n",
    "# CNN\n",
    "acc: 92.44%<br />\n",
    "Accuracy =  0.896222241883<br />\n",
    "Sensitivity =  0.530268199234<br />\n",
    "Specificity =  0.94398879776<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.1700000000000017\n",
      "0.8599999999999994\n",
      "5.82\n",
      "0.19999999999998863\n"
     ]
    }
   ],
   "source": [
    "# sklearn\n",
    "SAccuracy = 90.6 \n",
    "SSensitivity = 50.2\n",
    "SSpecificity = 95.9\n",
    "\n",
    "# MLP\n",
    "Macc=91.27\n",
    "MAccuracy =  90.48\n",
    "MSensitivity =  58.85\n",
    "MSpecificity =  94.60\n",
    "\n",
    "# CNN\n",
    "Cacc =92.44\n",
    "CAccuracy =  89.62\n",
    "CSensitivity =  53.03\n",
    "CSpecificity =  94.4\n",
    "\n",
    "print(Macc-Cacc)\n",
    "print(MAccuracy-CAccuracy)\n",
    "print(MSensitivity-CSensitivity)\n",
    "print(MSpecificity-CSpecificity)\n",
    "\n",
    "print(Macc-Cacc)\n",
    "print(MAccuracy-CAccuracy)\n",
    "print(MSensitivity-CSensitivity)\n",
    "print(MSpecificity-CSpecificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3000000000000114\n",
      "1.5\n"
     ]
    }
   ],
   "source": [
    "# sklearn\n",
    "SAccuracy = 90.6 \n",
    "SSensitivity = 50.2\n",
    "SSpecificity = 95.9\n",
    "\n",
    "# MLP\n",
    "Macc=91.27\n",
    "MAccuracy =  90.48\n",
    "MSensitivity =  58.85\n",
    "MSpecificity =  94.60\n",
    "\n",
    "# CNN\n",
    "Cacc =92.44\n",
    "CAccuracy =  89.62\n",
    "CSensitivity =  53.03\n",
    "CSpecificity =  94.4\n",
    "\n",
    "# print(SAccuracy-MAccuracy)\n",
    "# print(SAccuracy-CAccuracy)\n",
    "\n",
    "# print(SSensitivity-MSensitivity)\n",
    "# print(SSensitivity-CSensitivity)\n",
    "\n",
    "print(SSpecificity-MSpecificity)\n",
    "print(SSpecificity-CSpecificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sklearn\n",
    "SAccuracy = 90.6 \n",
    "SSensitivity = 50.2\n",
    "SSpecificity = 95.9\n",
    "\n",
    "# MLP\n",
    "Macc=91.27\n",
    "MAccuracy =  90.48\n",
    "MSensitivity =  58.85\n",
    "MSpecificity =  94.60\n",
    "\n",
    "# CNN\n",
    "Cacc =92.44\n",
    "CAccuracy =  89.62\n",
    "CSensitivity =  53.03\n",
    "CSpecificity =  94.4\n",
    "\n",
    "print(max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
